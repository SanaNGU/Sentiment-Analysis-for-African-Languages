{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf1uM7sJQVcI",
    "outputId": "ed6953ec-d3cc-4ae4-909b-03b23ad3438d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in /home/azime/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: clean-text in /home/azime/anaconda3/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text) (6.1.1)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text) (1.7.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/azime/anaconda3/lib/python3.9/site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
      "Requirement already satisfied: clean-text[sklearn] in /home/azime/anaconda3/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text[sklearn]) (6.1.1)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text[sklearn]) (1.7.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text[sklearn]) (1.0.2)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from clean-text[sklearn]) (1.4.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/azime/anaconda3/lib/python3.9/site-packages (from ftfy<7.0,>=6.0->clean-text[sklearn]) (0.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/azime/anaconda3/lib/python3.9/site-packages (from pandas<2.0.0,>=1.0.0->clean-text[sklearn]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/azime/anaconda3/lib/python3.9/site-packages (from pandas<2.0.0,>=1.0.0->clean-text[sklearn]) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/azime/anaconda3/lib/python3.9/site-packages (from pandas<2.0.0,>=1.0.0->clean-text[sklearn]) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/azime/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.0.0->clean-text[sklearn]) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.0.0->clean-text[sklearn]) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/azime/anaconda3/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.0.0->clean-text[sklearn]) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/azime/anaconda3/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.0.0->clean-text[sklearn]) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install demoji\n",
    "!python -m pip install clean-text\n",
    "!python -m pip install clean-text[sklearn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CC6FLRDVGOnC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#data processing\n",
    "import re, string\n",
    "import demoji\n",
    "from cleantext import clean\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE YEAR OF REVIVAL ሶምሶንም ስለ ሁለቱ ዓይኖቼ ፍልስጥኤማውያንን አሁን እንድበቀል እግዚአብሔር አምላክ ሆይ እባክህ አስበኝ አምላክ ሆይ ይህን አ'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = clean(tweet, \n",
    "                    fix_unicode=False,               # fix various unicode errors\n",
    "                    to_ascii=False,                  # transliterate to closest ASCII representation\n",
    "                    lower=False,                     # lowercase text\n",
    "                    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "                    no_urls=True,                  # replace all URLs with a special token\n",
    "                    no_emails=False,                # replace all email addresses with a special token\n",
    "                    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                    no_numbers=False,               # replace all numbers with a special token\n",
    "                    no_digits=False,                # replace all digits with a special token\n",
    "                    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "                    no_punct=True)\n",
    "    tweet = re.sub(r'\\\\x[0-9a-f][0-9a-f]', \"\", tweet)\n",
    "    tweet = re.sub('@(\\w)+', \"\", tweet)\n",
    "    tweet = re.sub('&amp', \"\", tweet)\n",
    "    tweet = re.sub('//t.co/(\\w)+', \"\",tweet)\n",
    "    tweet = re.sub('//t.c', \"\",tweet)\n",
    "    tweet = re.sub(r'\\\\',\"\", tweet)\n",
    "    tweet = re.sub('#',\"\", tweet)\n",
    "    tweet = re.sub(\"\\'\", \" \" ,tweet)\n",
    "    tweet = re.sub(\"user\", \"\" ,tweet)\n",
    "    \n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rgQ2u9M2xSt7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ma_dev.tsv', 'sw_train.tsv', 'am_dev.tsv', 'am_train.tsv', 'dz_dev.tsv', 'dz_train.tsv', 'ha_dev.tsv', 'ha_train.tsv', 'ig_dev.tsv', 'ig_train.tsv', 'kr_dev.tsv', 'kr_train.tsv', 'ma_train.tsv', 'pcm_dev.tsv', 'pcm_train.tsv', 'pt_dev.tsv', 'pt_train.tsv', 'sw_dev.tsv', 'ts_dev.tsv', 'ts_train.tsv', 'twi_dev.tsv', 'twi_train.tsv', 'yo_dev.tsv', 'yo_train.tsv']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "format_list = ['_dev.tsv','_train.tsv']\n",
    "file_list = [i for i in os.listdir('SubtaskA/') if format_list[0] in i or format_list[1] in i]\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= ma_dev.tsv========================\n",
      "hhhhhhhhhhhhhhhhhhhhhh ana ga3ma sma3tt ach kant kat9oll kanrakazz ghir m3a zineb oyassmin ochirine\n",
      "hhhhhhhhhhhhhhhhhhhhhh ana ga3ma sma3tt ach kant kat9oll kanrakazz ghir m3a zineb oyassmin ochirine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ma_dev_clean.tsv\n",
      "========================= sw_train.tsv========================\n",
      "Kwani tanesco wanakataga umeme makusudinadhani kuna changamoto behind zinatakiwa zitatuliwe na sio kutoa matamko\n",
      "Kwani tanesco wanakataga umeme makusudinadhani kuna changamoto behind zinatakiwa zitatuliwe na sio kutoa matamko\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sw_train_clean.tsv\n",
      "========================= am_dev.tsv========================\n",
      "The only part I like......ትልልቅ የነዳጅ ፍጆታ ያላቸው ተሽከርካሪዎች ከአየር ብክለት አኳያ፣ በነዳጅ ወጪም ረገድ ተለይተው ኤክሳይዝ ታክሱ ሊ…\n",
      "The only part I likeትልልቅ የነዳጅ ፍጆታ ያላቸው ተሽከርካሪዎች ከአየር ብክለት አኳያ በነዳጅ ወጪም ረገድ ተለይተው ኤክሳይዝ ታክሱ ሊ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "am_dev_clean.tsv\n",
      "========================= am_train.tsv========================\n",
      "Tesfaye ለካስ ጭብል ለብሰሽ የፕሮፌሰርን ፎቶ ለጥፈክ እልም ያልክ ባዳ ነክ እፈር ትንሽ\n",
      "Tesfaye ለካስ ጭብል ለብሰሽ የፕሮፌሰርን ፎቶ ለጥፈክ እልም ያልክ ባዳ ነክ እፈር ትንሽ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "am_train_clean.tsv\n",
      "========================= dz_dev.tsv========================\n",
      "@user @user @user ههههههههههههه شوفي تاريخ بلدك بعدها تحدثي عن تاريخ اسيادك ...حبيبتي انتِ غ… @user\n",
      "user user user ههههههههههههه شوفي تاريخ بلدك بعدها تحدثي عن تاريخ اسيادك حبيبتي انتِ غ user\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dz_dev_clean.tsv\n",
      "========================= dz_train.tsv========================\n",
      "@user على حسب موقعك يبدو أنك صاحب نظرة ثاقبة .يخي تبهليل . @user\n",
      "user على حسب موقعك يبدو أنك صاحب نظرة ثاقبة يخي تبهليل user\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dz_train_clean.tsv\n",
      "========================= ha_dev.tsv========================\n",
      "@user @user Allah ya kai rahmarsa kabarin ta 🤲🤲🤲😭😭 Uwa ga gimbiyar👑👑👑 Alhanislam Hauwa Maina\n",
      "user user Allah ya kai rahmarsa kabarin ta 🤲🤲🤲😭😭 Uwa ga gimbiyar👑👑👑 Alhanislam Hauwa Maina\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ha_dev_clean.tsv\n",
      "========================= ha_train.tsv========================\n",
      "@user Da kudin da Arewa babu wani abin azo agani da yayi wa alummah allah ya isa yacucemu wlh yarikitamana kasa yarikitamana kasuwanci harkar ilimi harkar lfy hanyoyi babu lantarki dasuransu komai yalalace ga cinhanci da rashawa a fili ko ina a Nigeria jamiyaryar su tabataman mlm 😭🗣\n",
      "user Da kudin da Arewa babu wani abin azo agani da yayi wa alummah allah ya isa yacucemu wlh yarikitamana kasa yarikitamana kasuwanci harkar ilimi harkar lfy hanyoyi babu lantarki dasuransu komai yalalace ga cinhanci da rashawa a fili ko ina a Nigeria jamiyaryar su tabataman mlm 😭🗣\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ha_train_clean.tsv\n",
      "========================= ig_dev.tsv========================\n",
      "Uche Chukwu ga emé... regardless . #NigeriaDecides2019\n",
      "Uche Chukwu ga emé regardless NigeriaDecides2019\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ig_dev_clean.tsv\n",
      "========================= ig_train.tsv========================\n",
      "Nna Ike Gwuru ooo. 😂 https://t.co/NDS7juFBGd\n",
      "Nna Ike Gwuru ooo 😂 <URL>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ig_train_clean.tsv\n",
      "========================= kr_dev.tsv========================\n",
      "Abavugaga ngo CHOGM2022 ntizabera mu Rwanda, ubwo bambwira niba Igikomangoma cy'ubwongereza cyari cyaje Mu Muryango_remezo cg inama y'ingobyi😂😂😂😂\n",
      "Abavugaga ngo CHOGM2022 ntizabera mu Rwanda ubwo bambwira niba Igikomangoma cyubwongereza cyari cyaje Mu Muryangoremezo cg inama yingobyi😂😂😂😂\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "kr_dev_clean.tsv\n",
      "========================= kr_train.tsv========================\n",
      "@user @user @user @user @user @user @user Hhhhhh ntabyihogoza, ubu x abo yishe bangana ik\n",
      "user user user user user user user Hhhhhh ntabyihogoza ubu x abo yishe bangana ik\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "kr_train_clean.tsv\n",
      "========================= ma_train.tsv========================\n",
      "hhhhhhhhhhhhhhhhhhhhhh ana ga3ma sma3tt ach kant kat9oll kanrakazz ghir m3a zineb oyassmin ochirine\n",
      "hhhhhhhhhhhhhhhhhhhhhh ana ga3ma sma3tt ach kant kat9oll kanrakazz ghir m3a zineb oyassmin ochirine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ma_train_clean.tsv\n",
      "========================= pcm_dev.tsv========================\n",
      "joke of a government na thunder way de do press up de wait una\n",
      "joke of a government na thunder way de do press up de wait una\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcm_dev_clean.tsv\n",
      "========================= pcm_train.tsv========================\n",
      "yeah ‍️the guy wants to trend dat was why e join nysc e cant trend with good music again\n",
      "yeah ‍️the guy wants to trend dat was why e join nysc e cant trend with good music again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcm_train_clean.tsv\n",
      "========================= pt_dev.tsv========================\n",
      "Eu amo meu país\n",
      "Eu amo meu país\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pt_dev_clean.tsv\n",
      "========================= pt_train.tsv========================\n",
      "Pedi uma resposta a Deus, ele deu me. Estou muito triste com ela. Mas mais tarde sei que vou entender.\n",
      "Pedi uma resposta a Deus ele deu me Estou muito triste com ela Mas mais tarde sei que vou entender\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pt_train_clean.tsv\n",
      "========================= sw_dev.tsv========================\n",
      "Leo nimepata kitambulisho changu cha taifa Asante sana\n",
      "Leo nimepata kitambulisho changu cha taifa Asante sana\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sw_dev_clean.tsv\n",
      "========================= ts_dev.tsv========================\n",
      "@user hiii woh ni danissa bae\n",
      "user hiii woh ni danissa bae\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ts_dev_clean.tsv\n",
      "========================= ts_train.tsv========================\n",
      "@user Loku u navela Ku tissunga, tissungue🕳️\n",
      "user Loku u navela Ku tissunga tissungue🕳️\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ts_train_clean.tsv\n",
      "========================= twi_dev.tsv========================\n",
      "hwan ba nie kasa by stomach s3 heart nso o\n",
      "hwan ba nie kasa by stomach s3 heart nso o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "twi_dev_clean.tsv\n",
      "========================= twi_train.tsv========================\n",
      "kako be shark but wo ti ewu\n",
      "kako be shark but wo ti ewu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "twi_train_clean.tsv\n",
      "========================= yo_dev.tsv========================\n",
      "Olódùmarè fúnmi láyọ̀ lọ́jọ́ òní. Sọ tèmi dire. Ọlọ́run Ọba gbémi lékè gbogbo ìṣòro.\n",
      "Olódùmarè fúnmi láyọ̀ lọ́jọ́ òní Sọ tèmi dire Ọlọ́run Ọba gbémi lékè gbogbo ìṣòro\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yo_dev_clean.tsv\n",
      "========================= yo_train.tsv========================\n",
      "Ìwọ ikú òpònú abaradúdú wọ, o ò ṣe é 're o. O d'óró, o ṣ'èkà, o m'ẹ́ni rere lọ. @user ṣe bẹ́ẹ̀ ó lọ.\n",
      "Ìwọ ikú òpònú abaradúdú wọ o ò ṣe é re o O dóró o ṣèkà o mẹ́ni rere lọ user ṣe bẹ́ẹ̀ ó lọ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yo_train_clean.tsv\n"
     ]
    }
   ],
   "source": [
    "for i in file_list:\n",
    "    print(f'========================= {i}========================')\n",
    "    df = pd.read_csv(f\"SubtaskA/{i}\",sep='\\t')\n",
    "    print(df['tweet'].values[])\n",
    "    df['tweet'] = df.tweet.apply(lambda x: clean_tweet(x))\n",
    "    print(df['tweet'].values[0])\n",
    "    print('\\n\\n\\n')\n",
    "    if '_dev' in i:\n",
    "        new_name = i.replace('_dev','_dev_clean')\n",
    "        print(new_name)\n",
    "        \n",
    "    elif '_train' in i:\n",
    "        new_name = i.replace('_train','_train_clean')\n",
    "        print(new_name)\n",
    "    \n",
    "    df.to_csv(f\"SubtaskA/{new_name}\",sep='\\t')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
